########################################
# Spark 3 → Spark 2 Compatibility Profile
########################################

### 1. ANSI / SQL behavior
spark.sql.ansi.enabled=false
spark.sql.storeAssignmentPolicy=LEGACY
spark.sql.legacy.useV1SourceList=parquet,avro,orc,json,csv
spark.sql.legacy.allowUntypedScalaUDF=true

### 2. Casting & Type Coercion
spark.sql.legacy.allowCastNumericToTimestamp=true
spark.sql.legacy.allowCastTimestampToNumeric=true
spark.sql.legacy.allowCastDateToTimestamp=true
spark.sql.legacy.allowCastTimestampToDate=true
spark.sql.legacy.typeCoercion.datetimeToString.enabled=true
spark.sql.legacy.typeCoercion.inConversion=true
spark.sql.legacy.typeCoercion.inSetConversion=true

### 3. Datetime / Calendar Rebase (parquet/orc/avro compatibility)
spark.sql.legacy.timeParserPolicy=LEGACY
spark.sql.legacy.parquet.datetimeRebaseModeInRead=LEGACY
spark.sql.legacy.parquet.datetimeRebaseModeInWrite=LEGACY
spark.sql.legacy.parquet.int96RebaseModeInRead=LEGACY
spark.sql.legacy.parquet.int96RebaseModeInWrite=LEGACY
spark.sql.legacy.orc.datetimeRebaseModeInRead=LEGACY
spark.sql.legacy.orc.datetimeRebaseModeInWrite=LEGACY
spark.sql.legacy.avro.datetimeRebaseModeInRead=LEGACY
spark.sql.legacy.avro.datetimeRebaseModeInWrite=LEGACY

### 4. Decimal & Numeric Handling
spark.sql.legacy.allowNegativeScaleOfDecimal=true
spark.sql.legacy.decimalOperations.allowPrecisionLoss=true

### 5. Null / Comparison Semantics
spark.sql.legacy.nullComparisonBehavior=true
spark.sql.legacy.nullOrdering.enabled=true   # legacy NULLS ordering

### 6. Hive & Table Metadata
spark.sql.legacy.createHiveTableByDefault=true
spark.sql.legacy.allowCreatingManagedTableUsingNonemptyLocation=true
spark.sql.legacy.charVarcharAsString=true

### 7. Joins & Ambiguous Columns
spark.sql.legacy.allowAmbiguousColumnName=true
spark.sql.crossJoin.enabled=true
spark.sql.legacy.cartesianProduct.enabled=true

### 8. Grouping / Rollup / Cube
spark.sql.legacy.groupingIdWithAppendedUserGroupBy=false

### 9. Case Sensitivity & Identifiers
spark.sql.caseSensitive=false
spark.sql.legacy.caseSensitiveInferenceMode=INFER_AND_SAVE
spark.sql.globalTempDatabase=global_temp

### 10. Miscellaneous Legacy Switches
spark.sql.legacy.sessionInitWithConfigDefaults=true
spark.sql.legacy.replaceDatabricksSparkAvro.enabled=true
spark.sql.legacy.interval.enabled=true
spark.sql.legacy.sizeOfNull=-1


########################################
# Runtime / Execution → Spark 2 Style
########################################

### Adaptive Query Execution (disabled in Spark 2)
spark.sql.adaptive.enabled=false
spark.sql.adaptive.coalescePartitions.enabled=false
spark.sql.adaptive.localShuffleReader.enabled=false
spark.sql.adaptive.skewJoin.enabled=false

### Shuffle Partitions (Spark 2 default = 200)
spark.sql.shuffle.partitions=200

### Broadcast Join Threshold (Spark 2 default = 10MB)
spark.sql.autoBroadcastJoinThreshold=10485760

### Join Strategy
spark.sql.join.preferSortMergeJoin=true

### Optimizer behavior
spark.sql.cbo.enabled=false
spark.sql.cbo.joinReorder.enabled=false
spark.sql.cbo.planStats.enabled=false

### Partition Pruning (disable Spark 3’s dynamic pruning)
spark.sql.optimizer.dynamicPartitionPruning.enabled=false